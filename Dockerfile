FROM python:3.12.12-slim-trixie

# è®¾ç½®çŽ¯å¢ƒå˜é‡é¿å…äº¤äº’å¼å®‰è£…
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# å®‰è£…å¿…è¦çš„ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    git \
    git-lfs \
    curl \
    wget \
    ca-certificates \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# å‡çº§ pip å¹¶å®‰è£… Python ä¾èµ–
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir \
    huggingface_hub \
    requests \
    tqdm

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /models

# è®¾ç½®çŽ¯å¢ƒå˜é‡ï¼ˆä»Žæž„å»ºå‚æ•°èŽ·å–ï¼‰
ARG HF_TOKEN
ARG MODEL_NAME
ARG HF_ENDPOINT=https://hf-mirror.com

ENV HUGGINGFACE_HUB_TOKEN=${HF_TOKEN}
ENV HF_ENDPOINT=${HF_ENDPOINT}

# åˆ›å»ºæ¨¡åž‹ç›®å½•
RUN mkdir -p /models

# ä¸‹è½½æ¨¡åž‹è„šæœ¬
RUN cat > /download_model.py << 'EOF'
import os
import sys
from huggingface_hub import snapshot_download
from pathlib import Path

def download_model():
    model_name = os.environ.get('MODEL_NAME')
    token = os.environ.get('HUGGINGFACE_HUB_TOKEN')
    
    if not model_name:
        print("Error: MODEL_NAME environment variable not set")
        sys.exit(1)
    
    # æå–æ¨¡åž‹åç§°çš„æœ€åŽéƒ¨åˆ†ä½œä¸ºç›®å½•å
    model_dir_name = model_name.split('/')[-1]
    local_dir = f"/models/{model_dir_name}"
    
    print(f"Downloading model: {model_name}")
    print(f"Target directory: {local_dir}")
    print(f"Using token: {'Yes' if token else 'No'}")
    
    try:
        snapshot_download(
            repo_id=model_name,
            local_dir=local_dir,
            local_dir_use_symlinks=False,
            token=token,
            resume_download=True
        )
        print(f"Successfully downloaded {model_name} to {local_dir}")
        
        # æ˜¾ç¤ºä¸‹è½½çš„æ–‡ä»¶
        print("\nDownloaded files:")
        for root, dirs, files in os.walk(local_dir):
            level = root.replace(local_dir, '').count(os.sep)
            indent = ' ' * 2 * level
            print(f"{indent}{os.path.basename(root)}/")
            subindent = ' ' * 2 * (level + 1)
            for file in files:
                file_path = os.path.join(root, file)
                file_size = os.path.getsize(file_path)
                size_mb = file_size / (1024 * 1024)
                print(f"{subindent}{file} ({size_mb:.1f}MB)")
                
    except Exception as e:
        print(f"Error downloading model: {e}")
        sys.exit(1)

if __name__ == "__main__":
    download_model()
EOF

# ä¸‹è½½æ¨¡åž‹
RUN python /download_model.py

# åˆ›å»ºæ¨¡åž‹ä¿¡æ¯è„šæœ¬
RUN cat > /model_info.py << 'EOF'
import os
import json
from pathlib import Path

def show_model_info():
    models_dir = Path("/models")
    
    print("=" * 60)
    print("ðŸ¤– MODEL STORAGE CONTAINER")
    print("=" * 60)
    
    if not models_dir.exists():
        print("âŒ No models directory found")
        return
    
    model_dirs = [d for d in models_dir.iterdir() if d.is_dir()]
    
    if not model_dirs:
        print("âŒ No models found")
        return
    
    for model_dir in model_dirs:
        print(f"\nðŸ“¦ Model: {model_dir.name}")
        print("-" * 40)
        
        # æ˜¾ç¤ºé…ç½®æ–‡ä»¶ä¿¡æ¯
        config_file = model_dir / "config.json"
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                print(f"ðŸ—ï¸  Architecture: {config.get('architectures', ['Unknown'])[0]}")
                print(f"ðŸ”¤ Model Type: {config.get('model_type', 'Unknown')}")
                if 'hidden_size' in config:
                    print(f"ðŸ“ Hidden Size: {config['hidden_size']}")
                if 'num_hidden_layers' in config:
                    print(f"ðŸ”¢ Layers: {config['num_hidden_layers']}")
            except:
                print("âš ï¸  Could not read config.json")
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨å’Œå¤§å°
        total_size = 0
        file_count = 0
        
        print(f"\nðŸ“ Files in {model_dir.name}:")
        for file_path in sorted(model_dir.rglob("*")):
            if file_path.is_file():
                file_size = file_path.stat().st_size
                total_size += file_size
                file_count += 1
                
                size_mb = file_size / (1024 * 1024)
                relative_path = file_path.relative_to(model_dir)
                
                if size_mb > 1:
                    print(f"  ðŸ“„ {relative_path} ({size_mb:.1f}MB)")
                else:
                    size_kb = file_size / 1024
                    print(f"  ðŸ“„ {relative_path} ({size_kb:.1f}KB)")
        
        total_gb = total_size / (1024 * 1024 * 1024)
        print(f"\nðŸ“Š Summary:")
        print(f"  â€¢ Total files: {file_count}")
        print(f"  â€¢ Total size: {total_gb:.2f}GB")
    
    print("\n" + "=" * 60)
    print("ðŸ’¡ Usage:")
    print("docker cp <container_name>:/models ./local-models")
    print("=" * 60)

if __name__ == "__main__":
    show_model_info()
EOF

# åˆ›å»ºç®€å•çš„åˆ—è¡¨è„šæœ¬
RUN cat > /list_models.sh << 'EOF'
#!/bin/bash
echo "ðŸ“‚ Models directory contents:"
ls -la /models/
echo ""
python /model_info.py
EOF

RUN chmod +x /list_models.sh

# è®¾ç½®é»˜è®¤å‘½ä»¤
CMD ["/list_models.sh"]

# æ·»åŠ å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD ls /models && echo "Models available" || exit 1

# æ·»åŠ æ ‡ç­¾ä¿¡æ¯
LABEL maintainer="your-email@example.com"
LABEL description="HuggingFace model storage container"
LABEL version="1.0"
